{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Demo\n",
    "\n",
    "Injection of first order logic rules into a neural network for iris classification task.\n",
    "\n",
    "Download antlr4 jar and create parser for Datalog.g4 grammar."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! wget https://www.antlr.org/download/antlr-4.9.2-complete.jar\n",
    "! export CLASSPATH=\"./antlr-4.9.2-complete.jar:$CLASSPATH\"\n",
    "! java -jar ./antlr-4.9.2-complete.jar -Dlanguage=Python3 resources/Datalog.g4 -visitor -o resources/dist\n",
    "! rm ./antlr-4.9.2-complete.jar"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-08 15:43:28--  https://www.antlr.org/download/antlr-4.9.2-complete.jar\r\n",
      "Resolving www.antlr.org (www.antlr.org)... 185.199.110.153, 185.199.109.153, 185.199.108.153, ...\r\n",
      "Connecting to www.antlr.org (www.antlr.org)|185.199.110.153|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 2100564 (2.0M) [application/java-archive]\r\n",
      "Saving to: ‘antlr-4.9.2-complete.jar’\r\n",
      "\r\n",
      "antlr-4.9.2-complet 100%[===================>]   2.00M  12.6MB/s    in 0.2s    \r\n",
      "\r\n",
      "2022-03-08 15:43:28 (12.6 MB/s) - ‘antlr-4.9.2-complete.jar’ saved [2100564/2100564]\r\n",
      "\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some import."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from antlr4 import InputStream, CommonTokenStream\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.framework.random_seed import set_random_seed\n",
    "from psyki.logic.datalog.grammar.adapters import Antlr4\n",
    "from resources.dist.resources.DatalogLexer import DatalogLexer\n",
    "from resources.dist.resources.DatalogParser import DatalogParser\n",
    "from psyki.ski.injectors import LambdaLayer\n",
    "from test.utils import get_mlp\n",
    "from test.resources.rules import get_rules\n",
    "from test.utils import get_processed_dataset, get_class_accuracy, get_f1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading iris dataset and separation into train and test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1., 10.,  1., ..., 12.,  1.,  1.],\n       [ 2., 11.,  2., ..., 12.,  2.,  1.],\n       [ 3., 12.,  3., ..., 10.,  3.,  1.],\n       ...,\n       [ 2.,  1.,  2., ...,  1.,  4., 13.],\n       [ 2., 12.,  4., ..., 12.,  4.,  9.],\n       [ 1.,  7.,  3., ...,  8.,  3.,  7.]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y = get_processed_dataset('poker')\n",
    "train_x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import Datalog rules."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "feature_mapping = {\n",
    "        'S1': 0,\n",
    "        'R1': 1,\n",
    "        'S2': 2,\n",
    "        'R2': 3,\n",
    "        'S3': 4,\n",
    "        'R3': 5,\n",
    "        'S4': 6,\n",
    "        'R4': 7,\n",
    "        'S5': 8,\n",
    "        'R5': 9\n",
    "    }\n",
    "\n",
    "class_mapping = {\n",
    "        'nothing': 0,\n",
    "        'pair': 1,\n",
    "        'two': 2,\n",
    "        'three': 3,\n",
    "        'straight': 4,\n",
    "        'flush': 5,\n",
    "        'full': 6,\n",
    "        'four': 7,\n",
    "        'straight_flush': 8,\n",
    "        'royal_flush': 9\n",
    "    }\n",
    "\n",
    "poker_rules = get_rules('poker')\n",
    "formulae = [Antlr4().get_formula(DatalogParser(CommonTokenStream(DatalogLexer(InputStream(rule)))).formula()) for rule in poker_rules]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Injection of fuzzy logic function derived from Datalog rules into a neural network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           704         Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           650         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 20)           0           Input[0][0]                      \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 10)           0           concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 5,514\n",
      "Trainable params: 5,514\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(0)\n",
    "input_features = Input((10,), name='Input')\n",
    "network = get_mlp(input_layer=input_features, output=10, layers=3, neurons=64, activation_function='relu', last_activation_function='softmax')\n",
    "model = Model(input_features, network)\n",
    "injector = LambdaLayer(model, class_mapping, feature_mapping)\n",
    "injector.inject(formulae)\n",
    "injector.predictor.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "injector.predictor.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 15:43:59.652821: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-03-08 15:43:59.652985: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 6ms/step - loss: 1.4096 - accuracy: 0.2789\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.3226 - accuracy: 0.3014\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.2981 - accuracy: 0.3404\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 1.2842 - accuracy: 0.3739\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 1.2728 - accuracy: 0.3810\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.2631 - accuracy: 0.3939\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.2534 - accuracy: 0.3994\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.2443 - accuracy: 0.4052\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.2344 - accuracy: 0.4083\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.2215 - accuracy: 0.4182\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.2101 - accuracy: 0.4178\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.1963 - accuracy: 0.4213\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.1840 - accuracy: 0.4261\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.1697 - accuracy: 0.4323\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.1482 - accuracy: 0.4426\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.1306 - accuracy: 0.4527\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 1.1132 - accuracy: 0.4630\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.0942 - accuracy: 0.4718\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 1.0737 - accuracy: 0.4841\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.0520 - accuracy: 0.4972\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.0342 - accuracy: 0.5081\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 1.0038 - accuracy: 0.5237\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.9784 - accuracy: 0.5438\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.9567 - accuracy: 0.5550\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.9302 - accuracy: 0.5684\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.9127 - accuracy: 0.5815\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.8893 - accuracy: 0.5906\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.8701 - accuracy: 0.6030\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.8451 - accuracy: 0.6147\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.8284 - accuracy: 0.6240\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.8097 - accuracy: 0.6333\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.7899 - accuracy: 0.6437\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.7737 - accuracy: 0.6508\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.7563 - accuracy: 0.6623\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.7328 - accuracy: 0.6725\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.7131 - accuracy: 0.6845\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.6944 - accuracy: 0.6924\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.6821 - accuracy: 0.7003\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.6586 - accuracy: 0.7114\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.6373 - accuracy: 0.7248\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.6225 - accuracy: 0.7305\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.5950 - accuracy: 0.7437\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.5734 - accuracy: 0.7551\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.5532 - accuracy: 0.7673\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.5272 - accuracy: 0.7805\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.5069 - accuracy: 0.7905\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4781 - accuracy: 0.8048\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4570 - accuracy: 0.8161\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4337 - accuracy: 0.8261\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4064 - accuracy: 0.8409\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3828 - accuracy: 0.8496\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3573 - accuracy: 0.8649\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3313 - accuracy: 0.8762\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3162 - accuracy: 0.8840\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2879 - accuracy: 0.8952\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2704 - accuracy: 0.9045\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2584 - accuracy: 0.9088\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2335 - accuracy: 0.9209\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2225 - accuracy: 0.9264\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.2069 - accuracy: 0.9333\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1983 - accuracy: 0.9375\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1819 - accuracy: 0.9444\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1700 - accuracy: 0.9491\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1632 - accuracy: 0.9507\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1627 - accuracy: 0.9511\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1494 - accuracy: 0.9569\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1388 - accuracy: 0.9612\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1348 - accuracy: 0.9615\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1277 - accuracy: 0.9645\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1252 - accuracy: 0.9655\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1157 - accuracy: 0.9685\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1145 - accuracy: 0.9701\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.1158 - accuracy: 0.9671\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.1081 - accuracy: 0.9705\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1046 - accuracy: 0.9719\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.1041 - accuracy: 0.9715\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0916 - accuracy: 0.9770\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0993 - accuracy: 0.9729\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0931 - accuracy: 0.9759\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0972 - accuracy: 0.9731\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0813 - accuracy: 0.9791\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0862 - accuracy: 0.9769\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0823 - accuracy: 0.9784\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0874 - accuracy: 0.9766\n",
      "Epoch 85/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0755 - accuracy: 0.9807\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0776 - accuracy: 0.9790\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0804 - accuracy: 0.9800\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0729 - accuracy: 0.9814\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0721 - accuracy: 0.9820\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0711 - accuracy: 0.9824\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0654 - accuracy: 0.9841\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0755 - accuracy: 0.9793\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0635 - accuracy: 0.9843\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0650 - accuracy: 0.9842\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0572 - accuracy: 0.9857\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0572 - accuracy: 0.9859\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0662 - accuracy: 0.9823\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0534 - accuracy: 0.9876\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0580 - accuracy: 0.9852\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0593 - accuracy: 0.9844\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x138e2a190>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injector.predictor.fit(train_x, train_y, verbose=1, batch_size=32, epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Removing the injected rules from the network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                704       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,514\n",
      "Trainable params: 5,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "injector.remove()\n",
    "injector.predictor.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "injector.predictor.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31250/31250 [==============================] - 6s 197us/step - loss: 0.0710 - accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.0710061639547348, 0.9889299869537354]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injector.predictor.evaluate(test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.9981345107529992,\n 0.9991171555841685,\n 0.9450044097265969,\n 0.9130249514701009,\n 0.5009009009009009,\n 0.002004008016032064,\n 0.20154494382022473,\n 0.030434782608695653,\n 0.0,\n 0.0]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies, weights = get_class_accuracy(injector.predictor, test_x, test_y)\n",
    "accuracies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0.47804124773305096"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_f1(injector.predictor, test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The same network without knowledge injection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                704       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,514\n",
      "Trainable params: 5,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(0)\n",
    "input_features = Input((10,), name='Input')\n",
    "network = get_mlp(input_layer=input_features, output=10, layers=3, neurons=64, activation_function='relu', last_activation_function='softmax')\n",
    "model = Model(input_features, network)\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "782/782 [==============================] - 0s 363us/step - loss: 1.0413 - accuracy: 0.4912\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.9710 - accuracy: 0.5263\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.9570 - accuracy: 0.5398\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.9496 - accuracy: 0.5455\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.9406 - accuracy: 0.5541\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 0s 363us/step - loss: 0.9340 - accuracy: 0.5612\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.9261 - accuracy: 0.5595\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.9191 - accuracy: 0.5701\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.9123 - accuracy: 0.5746\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.9036 - accuracy: 0.5827\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 0s 359us/step - loss: 0.8939 - accuracy: 0.5859\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.8838 - accuracy: 0.5943\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 0s 359us/step - loss: 0.8764 - accuracy: 0.6021\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 0s 364us/step - loss: 0.8633 - accuracy: 0.6153\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.8494 - accuracy: 0.6191\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.8352 - accuracy: 0.6321\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.8234 - accuracy: 0.6411\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 0s 362us/step - loss: 0.8090 - accuracy: 0.6468\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.7961 - accuracy: 0.6568\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 0s 357us/step - loss: 0.7793 - accuracy: 0.6644\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 0s 357us/step - loss: 0.7648 - accuracy: 0.6726\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.7462 - accuracy: 0.6818\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.7342 - accuracy: 0.6878\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 0s 359us/step - loss: 0.7179 - accuracy: 0.6941\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 0s 358us/step - loss: 0.7015 - accuracy: 0.6993\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.6889 - accuracy: 0.7110\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 0s 363us/step - loss: 0.6710 - accuracy: 0.7203\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.6553 - accuracy: 0.7281\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.6402 - accuracy: 0.7330\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 0s 359us/step - loss: 0.6244 - accuracy: 0.7435\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.6091 - accuracy: 0.7514\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 0s 367us/step - loss: 0.5924 - accuracy: 0.7599\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.5766 - accuracy: 0.7645\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 0s 358us/step - loss: 0.5634 - accuracy: 0.7738\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 0s 359us/step - loss: 0.5414 - accuracy: 0.7854\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 0s 365us/step - loss: 0.5234 - accuracy: 0.7924\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 0s 370us/step - loss: 0.5030 - accuracy: 0.8011\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 0s 359us/step - loss: 0.4930 - accuracy: 0.8089\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 0s 363us/step - loss: 0.4750 - accuracy: 0.8159\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 0s 363us/step - loss: 0.4554 - accuracy: 0.8272\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 0s 356us/step - loss: 0.4353 - accuracy: 0.8359\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.4226 - accuracy: 0.8434\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 0s 363us/step - loss: 0.4029 - accuracy: 0.8507\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 0s 362us/step - loss: 0.3834 - accuracy: 0.8620\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 0s 376us/step - loss: 0.3650 - accuracy: 0.8700\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 0s 359us/step - loss: 0.3514 - accuracy: 0.8771\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.3316 - accuracy: 0.8843\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 0s 362us/step - loss: 0.3187 - accuracy: 0.8891\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 0s 363us/step - loss: 0.3072 - accuracy: 0.8958\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 0s 363us/step - loss: 0.2892 - accuracy: 0.9043\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.2762 - accuracy: 0.9077\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.2708 - accuracy: 0.9111\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.2445 - accuracy: 0.9238\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.2448 - accuracy: 0.9197\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 0s 358us/step - loss: 0.2260 - accuracy: 0.9288\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 0s 358us/step - loss: 0.2109 - accuracy: 0.9351\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.2027 - accuracy: 0.9377\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 0s 362us/step - loss: 0.1863 - accuracy: 0.9457\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 0s 359us/step - loss: 0.1744 - accuracy: 0.9508\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 0s 362us/step - loss: 0.1660 - accuracy: 0.9541\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.1575 - accuracy: 0.9559\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 0s 362us/step - loss: 0.1557 - accuracy: 0.9565\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.1358 - accuracy: 0.9649\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.1324 - accuracy: 0.9669\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 0s 353us/step - loss: 0.1343 - accuracy: 0.9628\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 0s 364us/step - loss: 0.1247 - accuracy: 0.9678\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.1182 - accuracy: 0.9697\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.1113 - accuracy: 0.9728\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 0s 358us/step - loss: 0.1116 - accuracy: 0.9707\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 0s 359us/step - loss: 0.1038 - accuracy: 0.9754\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 0s 363us/step - loss: 0.1003 - accuracy: 0.9762\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 0s 362us/step - loss: 0.1002 - accuracy: 0.9747\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 0s 365us/step - loss: 0.0925 - accuracy: 0.9782\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 0s 363us/step - loss: 0.0953 - accuracy: 0.9764\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 0s 363us/step - loss: 0.0841 - accuracy: 0.9803\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 0s 362us/step - loss: 0.0930 - accuracy: 0.9758\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.0775 - accuracy: 0.9825\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.0915 - accuracy: 0.9765\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 0s 359us/step - loss: 0.0740 - accuracy: 0.9832\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 0s 357us/step - loss: 0.0793 - accuracy: 0.9804\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 0s 354us/step - loss: 0.0682 - accuracy: 0.9846\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 0s 355us/step - loss: 0.0747 - accuracy: 0.9814\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 0s 356us/step - loss: 0.0725 - accuracy: 0.9832\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 0s 359us/step - loss: 0.0671 - accuracy: 0.9839\n",
      "Epoch 85/100\n",
      "782/782 [==============================] - 0s 354us/step - loss: 0.0701 - accuracy: 0.9834\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 0s 351us/step - loss: 0.0591 - accuracy: 0.9873\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 0s 359us/step - loss: 0.0649 - accuracy: 0.9848\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 0s 356us/step - loss: 0.0631 - accuracy: 0.9850\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 0s 354us/step - loss: 0.0625 - accuracy: 0.9852\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 0s 358us/step - loss: 0.0619 - accuracy: 0.9836\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 0s 365us/step - loss: 0.0647 - accuracy: 0.9844\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.0488 - accuracy: 0.9892\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 0s 363us/step - loss: 0.0570 - accuracy: 0.9871\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 0s 362us/step - loss: 0.0688 - accuracy: 0.9833\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 0s 366us/step - loss: 0.0477 - accuracy: 0.9896\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.0601 - accuracy: 0.9843\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.0473 - accuracy: 0.9897\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.0535 - accuracy: 0.9865\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.0481 - accuracy: 0.9892\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 0s 352us/step - loss: 0.0454 - accuracy: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x159a3ff40>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, verbose=1, batch_size=32, epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31250/31250 [==============================] - 6s 196us/step - loss: 0.1261 - accuracy: 0.9664\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.1261490285396576, 0.9664030075073242]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.9944434357723025,\n 0.966158419684827,\n 0.8478224350090294,\n 0.871028833862033,\n 0.15933075933075933,\n 0.011523046092184368,\n 0.2478932584269663,\n 0.05217391304347826,\n 0.0,\n 0.0]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies, weights = get_class_accuracy(model, test_x, test_y)\n",
    "accuracies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4355657347081636"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_f1(model, test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}