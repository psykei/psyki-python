{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Use case of PSyKI\n",
    "\n",
    "This is a brief demonstration of PSyKI.\n",
    "All steps of the symbolic knowledge injection workflow will be addressed.\n",
    "We will use some well known datasets for classification tasks for the demonstration.\n",
    "\n",
    "Importing injectors and utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from psyki.logic.datalog.grammar.adapters.antlr4 import get_formula_from_string\n",
    "from psyki.ski.injectors import NetworkComposer, LambdaLayer\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python.framework.random_seed import set_random_seed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import Input\n",
    "from test.resources.rules import get_rules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IRIS\n",
    "### Iris dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n3                  4.6               3.1                1.5               0.2   \n149                5.9               3.0                5.1               1.8   \n98                 5.1               2.5                3.0               1.1   \n6                  4.6               3.4                1.4               0.3   \n68                 6.2               2.2                4.5               1.5   \n..                 ...               ...                ...               ...   \n9                  4.9               3.1                1.5               0.1   \n103                6.3               2.9                5.6               1.8   \n67                 5.8               2.7                4.1               1.0   \n117                7.7               3.8                6.7               2.2   \n47                 4.6               3.2                1.4               0.2   \n\n     target  \n3         0  \n149       2  \n98        1  \n6         0  \n68        1  \n..      ...  \n9         0  \n103       2  \n67        1  \n117       2  \n47        0  \n\n[75 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>5.1</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>1.1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4.6</td>\n      <td>3.4</td>\n      <td>1.4</td>\n      <td>0.3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>6.2</td>\n      <td>2.2</td>\n      <td>4.5</td>\n      <td>1.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4.9</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>6.3</td>\n      <td>2.9</td>\n      <td>5.6</td>\n      <td>1.8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>5.8</td>\n      <td>2.7</td>\n      <td>4.1</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>7.7</td>\n      <td>3.8</td>\n      <td>6.7</td>\n      <td>2.2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>4.6</td>\n      <td>3.2</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 0\n",
    "set_random_seed(SEED)\n",
    "\n",
    "x, y = load_iris(return_X_y=True, as_frame=True)\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoder.fit_transform([y])\n",
    "dataset = x.join(y)\n",
    "train, test = train_test_split(dataset, test_size=0.5, random_state=SEED)\n",
    "train_x, train_y = train.iloc[:, :-1], train.iloc[:, -1]\n",
    "test_x, test_y = test.iloc[:, :-1], test.iloc[:, -1]\n",
    "\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris knowledge"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class(PL,PW,SL,SW,setosa)←((PL)≤(2.28))\n",
      "class(PL,PW,SL,SW,virginica)←((((PL)>(2.28)))∧(((PW)>(1.64))))\n",
      "class(PL,PW,SL,SW,versicolor)←((((PL)>(2.28)))∧(((PW)≤(1.64))))\n"
     ]
    }
   ],
   "source": [
    "class_mapping = {'setosa': 0, 'virginica': 1, 'versicolor': 2}\n",
    "variable_mapping = {'SL': 0, 'SW': 1, 'PL': 2, 'PW': 3}\n",
    "formulae = [get_formula_from_string(rule) for rule in get_rules('iris')]\n",
    "\n",
    "for formula in formulae:\n",
    "    print(formula)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris Predictor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                80        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 403\n",
      "Trainable params: 403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input((4,))\n",
    "x = Dense(16, activation='relu')(input_layer)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "x = Dense(3, activation='softmax')(x)\n",
    "\n",
    "predictor = Model(input_layer, x)\n",
    "predictor.compile('adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "predictor.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Injection via Lambda Layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"constrained_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           80          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16)           272         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 3)            51          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 7)            0           ['input_1[0][0]',                \n",
      "                                                                  'dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 3)            0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 403\n",
      "Trainable params: 403\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "injector = LambdaLayer(predictor, class_mapping, variable_mapping)\n",
    "constrained_predictor = injector.inject(formulae)\n",
    "constrained_predictor.compile('adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "constrained_predictor.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 10:59:11.852221: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 701us/step - loss: 1.1905 - accuracy: 0.4800\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 696us/step - loss: 0.9696 - accuracy: 0.7333\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 844us/step - loss: 0.7904 - accuracy: 0.7467\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 915us/step - loss: 0.6343 - accuracy: 0.8267\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 732us/step - loss: 0.5131 - accuracy: 0.9067\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 749us/step - loss: 0.4188 - accuracy: 0.9467\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 868us/step - loss: 0.3568 - accuracy: 0.9467\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 911us/step - loss: 0.3137 - accuracy: 0.9467\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 843us/step - loss: 0.2854 - accuracy: 0.9733\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 881us/step - loss: 0.2652 - accuracy: 0.9733\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 797us/step - loss: 0.2490 - accuracy: 0.9600\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 757us/step - loss: 0.2366 - accuracy: 0.9600\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 783us/step - loss: 0.2263 - accuracy: 0.9600\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 742us/step - loss: 0.2152 - accuracy: 0.9733\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 839us/step - loss: 0.2074 - accuracy: 0.9600\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 731us/step - loss: 0.2016 - accuracy: 0.9467\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 739us/step - loss: 0.1919 - accuracy: 0.9600\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 879us/step - loss: 0.1870 - accuracy: 0.9733\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 891us/step - loss: 0.1826 - accuracy: 0.9600\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 883us/step - loss: 0.1759 - accuracy: 0.9600\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 678us/step - loss: 0.1710 - accuracy: 0.9733\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 780us/step - loss: 0.1668 - accuracy: 0.9733\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 693us/step - loss: 0.1665 - accuracy: 0.9867\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 754us/step - loss: 0.1655 - accuracy: 0.9467\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 771us/step - loss: 0.1549 - accuracy: 0.9733\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 835us/step - loss: 0.1515 - accuracy: 0.9867\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 761us/step - loss: 0.1491 - accuracy: 0.9600\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 748us/step - loss: 0.1466 - accuracy: 0.9733\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 756us/step - loss: 0.1458 - accuracy: 0.9600\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 704us/step - loss: 0.1383 - accuracy: 0.9733\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 761us/step - loss: 0.1373 - accuracy: 0.9867\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 970us/step - loss: 0.1336 - accuracy: 0.9867\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 676us/step - loss: 0.1323 - accuracy: 0.9600\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 601us/step - loss: 0.1281 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 707us/step - loss: 0.1319 - accuracy: 0.9867\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 732us/step - loss: 0.1355 - accuracy: 0.9600\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 740us/step - loss: 0.1224 - accuracy: 0.9867\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 903us/step - loss: 0.1203 - accuracy: 0.9733\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 736us/step - loss: 0.1170 - accuracy: 0.9867\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 798us/step - loss: 0.1192 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 760us/step - loss: 0.1203 - accuracy: 0.9733\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 742us/step - loss: 0.1203 - accuracy: 0.9600\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 852us/step - loss: 0.1105 - accuracy: 0.9733\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 827us/step - loss: 0.1090 - accuracy: 0.9733\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 738us/step - loss: 0.1083 - accuracy: 0.9733\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 757us/step - loss: 0.1066 - accuracy: 0.9867\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 676us/step - loss: 0.1055 - accuracy: 0.9867\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 742us/step - loss: 0.1042 - accuracy: 0.9733\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 729us/step - loss: 0.1051 - accuracy: 0.9733\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 859us/step - loss: 0.1043 - accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x288a55c70>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constrained_predictor.fit(train_x, train_y, batch_size=8, epochs=50, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Removing constraints and testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 703us/step - loss: 0.1761 - accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9733333587646484"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictor = constrained_predictor.remove_constraints()\n",
    "new_predictor.compile('adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "loss, accuracy = new_predictor.evaluate(test_x, test_y)\n",
    "\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Injection via Network Composer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " lambda_8 (Lambda)              (None, 1)            0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1)            5           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 1)            0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            5           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 1)            0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            5           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 1)            0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1)            5           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              (None, 1)            0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1)            5           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 2)            0           ['lambda_8[0][0]',               \n",
      "                                                                  'dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 2)            0           ['lambda_8[0][0]',               \n",
      "                                                                  'dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 2)            0           ['lambda_1[0][0]',               \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 2)            0           ['lambda_1[0][0]',               \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 2)            0           ['lambda_3[0][0]',               \n",
      "                                                                  'dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 2)            0           ['lambda_4[0][0]',               \n",
      "                                                                  'dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 2)            0           ['lambda_7[0][0]',               \n",
      "                                                                  'dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 1)            3           ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1)            3           ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           80          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            3           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            3           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1)            3           ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 1)            3           ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 1)            3           ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " maximum_2 (Maximum)            (None, 1)            0           ['dense_20[0][0]',               \n",
      "                                                                  'dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16)           272         ['dense[1][0]']                  \n",
      "                                                                                                  \n",
      " maximum (Maximum)              (None, 1)            0           ['dense_4[0][0]',                \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " minimum (Minimum)              (None, 1)            0           ['dense_10[0][0]',               \n",
      "                                                                  'dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " minimum_2 (Minimum)            (None, 1)            0           ['dense_18[0][0]',               \n",
      "                                                                  'maximum_2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 19)           0           ['dense_1[1][0]',                \n",
      "                                                                  'maximum[0][0]',                \n",
      "                                                                  'minimum[0][0]',                \n",
      "                                                                  'minimum_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 3)            60          ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 458\n",
      "Trainable params: 412\n",
      "Non-trainable params: 46\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "injector = NetworkComposer(predictor, variable_mapping, layer=2)\n",
    "structured_predictor = injector.inject(formulae)\n",
    "structured_predictor.compile('adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "structured_predictor.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 646us/step - loss: 0.9612 - accuracy: 0.5733\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 653us/step - loss: 0.8363 - accuracy: 0.5733\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 642us/step - loss: 0.7568 - accuracy: 0.6267\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 593us/step - loss: 0.7070 - accuracy: 0.7333\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 733us/step - loss: 0.6631 - accuracy: 0.7333\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 750us/step - loss: 0.6295 - accuracy: 0.7333\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 522us/step - loss: 0.6015 - accuracy: 0.7333\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 609us/step - loss: 0.5723 - accuracy: 0.7333\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 602us/step - loss: 0.5457 - accuracy: 0.7333\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 603us/step - loss: 0.5189 - accuracy: 0.7333\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 657us/step - loss: 0.4927 - accuracy: 0.7333\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 533us/step - loss: 0.4776 - accuracy: 0.7333\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 573us/step - loss: 0.4580 - accuracy: 0.7333\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 563us/step - loss: 0.4425 - accuracy: 0.7333\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 530us/step - loss: 0.4296 - accuracy: 0.7333\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 503us/step - loss: 0.4177 - accuracy: 0.7333\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 539us/step - loss: 0.4066 - accuracy: 0.7333\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 516us/step - loss: 0.3964 - accuracy: 0.7467\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 583us/step - loss: 0.3869 - accuracy: 0.7600\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 807us/step - loss: 0.3782 - accuracy: 0.7600\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 659us/step - loss: 0.3681 - accuracy: 0.8267\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 550us/step - loss: 0.3597 - accuracy: 0.8933\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 618us/step - loss: 0.3538 - accuracy: 0.9067\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 568us/step - loss: 0.3441 - accuracy: 0.8667\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 557us/step - loss: 0.3267 - accuracy: 0.8933\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 469us/step - loss: 0.3158 - accuracy: 0.9200\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 548us/step - loss: 0.3072 - accuracy: 0.9200\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 544us/step - loss: 0.3001 - accuracy: 0.9333\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 556us/step - loss: 0.2945 - accuracy: 0.9067\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 584us/step - loss: 0.2813 - accuracy: 0.9200\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 562us/step - loss: 0.2738 - accuracy: 0.9333\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 592us/step - loss: 0.2678 - accuracy: 0.9333\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 622us/step - loss: 0.2598 - accuracy: 0.9200\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 608us/step - loss: 0.2524 - accuracy: 0.9333\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 581us/step - loss: 0.2475 - accuracy: 0.9600\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 543us/step - loss: 0.2450 - accuracy: 0.9467\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 635us/step - loss: 0.2300 - accuracy: 0.9467\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 559us/step - loss: 0.2231 - accuracy: 0.9467\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 654us/step - loss: 0.2154 - accuracy: 0.9467\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 578us/step - loss: 0.2106 - accuracy: 0.9600\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 528us/step - loss: 0.2099 - accuracy: 0.9467\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 656us/step - loss: 0.2048 - accuracy: 0.9600\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 523us/step - loss: 0.1888 - accuracy: 0.9600\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 532us/step - loss: 0.1845 - accuracy: 0.9467\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 459us/step - loss: 0.1801 - accuracy: 0.9467\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 594us/step - loss: 0.1758 - accuracy: 0.9600\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 554us/step - loss: 0.1718 - accuracy: 0.9733\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 543us/step - loss: 0.1674 - accuracy: 0.9467\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 555us/step - loss: 0.1656 - accuracy: 0.9467\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 520us/step - loss: 0.1623 - accuracy: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x288cfaf70>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_predictor.fit(train_x, train_y, batch_size=8, epochs=50, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 726us/step - loss: 0.2033 - accuracy: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9866666793823242"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = structured_predictor.evaluate(test_x, test_y)\n",
    "\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Without prior knowledge"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 494us/step - loss: 1.0727 - accuracy: 0.7333\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 488us/step - loss: 0.8754 - accuracy: 0.7333\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 465us/step - loss: 0.7173 - accuracy: 0.7333\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 737us/step - loss: 0.5899 - accuracy: 0.7600\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 533us/step - loss: 0.5031 - accuracy: 0.8533\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.9067\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.9067\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 578us/step - loss: 0.3436 - accuracy: 0.9067\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 550us/step - loss: 0.3192 - accuracy: 0.9200\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 573us/step - loss: 0.2993 - accuracy: 0.9467\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 457us/step - loss: 0.2821 - accuracy: 0.9333\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 434us/step - loss: 0.2702 - accuracy: 0.9067\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 491us/step - loss: 0.2597 - accuracy: 0.9333\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 445us/step - loss: 0.2461 - accuracy: 0.9467\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 508us/step - loss: 0.2377 - accuracy: 0.9467\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 638us/step - loss: 0.2308 - accuracy: 0.9333\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 516us/step - loss: 0.2193 - accuracy: 0.9467\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 512us/step - loss: 0.2145 - accuracy: 0.9600\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 449us/step - loss: 0.2090 - accuracy: 0.9467\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 454us/step - loss: 0.2004 - accuracy: 0.9467\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 478us/step - loss: 0.1947 - accuracy: 0.9600\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 461us/step - loss: 0.1893 - accuracy: 0.9600\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 459us/step - loss: 0.1898 - accuracy: 0.9600\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 539us/step - loss: 0.1878 - accuracy: 0.9467\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 424us/step - loss: 0.1751 - accuracy: 0.9467\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 451us/step - loss: 0.1711 - accuracy: 0.9733\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 499us/step - loss: 0.1681 - accuracy: 0.9600\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 488us/step - loss: 0.1659 - accuracy: 0.9600\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 487us/step - loss: 0.1644 - accuracy: 0.9467\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 451us/step - loss: 0.1545 - accuracy: 0.9600\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 453us/step - loss: 0.1532 - accuracy: 0.9733\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 537us/step - loss: 0.1490 - accuracy: 0.9600\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 459us/step - loss: 0.1475 - accuracy: 0.9600\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 350us/step - loss: 0.1426 - accuracy: 0.9600\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 346us/step - loss: 0.1464 - accuracy: 0.9733\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 416us/step - loss: 0.1509 - accuracy: 0.9600\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 349us/step - loss: 0.1350 - accuracy: 0.9600\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 358us/step - loss: 0.1326 - accuracy: 0.9600\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 485us/step - loss: 0.1289 - accuracy: 0.9600\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 469us/step - loss: 0.1317 - accuracy: 0.9867\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 414us/step - loss: 0.1332 - accuracy: 0.9600\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 435us/step - loss: 0.1330 - accuracy: 0.9600\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 422us/step - loss: 0.1207 - accuracy: 0.9733\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 514us/step - loss: 0.1192 - accuracy: 0.9600\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 463us/step - loss: 0.1179 - accuracy: 0.9600\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 429us/step - loss: 0.1162 - accuracy: 0.9867\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 401us/step - loss: 0.1145 - accuracy: 0.9867\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 514us/step - loss: 0.1132 - accuracy: 0.9600\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 457us/step - loss: 0.1140 - accuracy: 0.9600\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 460us/step - loss: 0.1128 - accuracy: 0.9600\n",
      "3/3 [==============================] - 0s 646us/step - loss: 0.1408 - accuracy: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9866666793823242"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(train_x, train_y, batch_size=8, epochs=50, verbose=1)\n",
    "loss, accuracy = predictor.evaluate(test_x, test_y)\n",
    "\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Observations\n",
    "\n",
    "In the previous examples we injected three logic rules into a sub-symbolic predictor (a neural network) with two different techniques.\n",
    "Both techniques have similar performance w.r.t. the same predictor trained without the usage of prior knowledge.\n",
    "The main reason is that the task is far too simple for a neural network and additional knowledge is not needed.\n",
    "Let's see the injection in a more challenging task.\n",
    "\n",
    "## Primate splice-junction gene sequences dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "     -30 -29 -28 -27 -26 -25 -24 -23 -22 -21  ... 22 23 24 25 26 27 28 29 30  \\\n0      c   c   a   g   c   t   g   c   a   t  ...  g  c  c  a  g  t  c  t  g   \n1      a   g   a   c   c   c   g   c   c   g  ...  t  g  c  c  c  c  c  g  c   \n2      g   a   g   g   t   g   a   a   g   g  ...  a  c  g  g  g  g  a  t  g   \n3      g   g   g   c   t   g   c   g   t   t  ...  g  t  t  t  t  c  c  c  c   \n4      g   c   t   c   a   g   c   c   c   c  ...  c  t  t  g  a  c  c  c  t   \n...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ... .. .. .. .. .. .. .. .. ..   \n3185   t   c   t   c   t   t   c   c   c   t  ...  t  c  c  t  c  t  c  t  t   \n3186   g   a   g   c   t   c   c   c   a   g  ...  g  c  a  c  a  g  c  t  g   \n3187   t   c   t   c   g   g   g   g   g   c  ...  g  t  g  t  g  t  g  t  c   \n3188   a   t   t   c   t   a   c   t   t   a  ...  c  c  a  a  a  a  c  a  a   \n3189   a   g   g   c   t   g   c   c   t   a  ...  a  g  t  a  c  c  a  t  t   \n\n     target  \n0        ei  \n1        ei  \n2        ei  \n3        ei  \n4        ei  \n...     ...  \n3185      n  \n3186      n  \n3187      n  \n3188      n  \n3189      n  \n\n[3190 rows x 61 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>-30</th>\n      <th>-29</th>\n      <th>-28</th>\n      <th>-27</th>\n      <th>-26</th>\n      <th>-25</th>\n      <th>-24</th>\n      <th>-23</th>\n      <th>-22</th>\n      <th>-21</th>\n      <th>...</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>c</td>\n      <td>c</td>\n      <td>a</td>\n      <td>g</td>\n      <td>c</td>\n      <td>t</td>\n      <td>g</td>\n      <td>c</td>\n      <td>a</td>\n      <td>t</td>\n      <td>...</td>\n      <td>g</td>\n      <td>c</td>\n      <td>c</td>\n      <td>a</td>\n      <td>g</td>\n      <td>t</td>\n      <td>c</td>\n      <td>t</td>\n      <td>g</td>\n      <td>ei</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>g</td>\n      <td>a</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>g</td>\n      <td>c</td>\n      <td>c</td>\n      <td>g</td>\n      <td>...</td>\n      <td>t</td>\n      <td>g</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>g</td>\n      <td>c</td>\n      <td>ei</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>g</td>\n      <td>a</td>\n      <td>g</td>\n      <td>g</td>\n      <td>t</td>\n      <td>g</td>\n      <td>a</td>\n      <td>a</td>\n      <td>g</td>\n      <td>g</td>\n      <td>...</td>\n      <td>a</td>\n      <td>c</td>\n      <td>g</td>\n      <td>g</td>\n      <td>g</td>\n      <td>g</td>\n      <td>a</td>\n      <td>t</td>\n      <td>g</td>\n      <td>ei</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>g</td>\n      <td>g</td>\n      <td>g</td>\n      <td>c</td>\n      <td>t</td>\n      <td>g</td>\n      <td>c</td>\n      <td>g</td>\n      <td>t</td>\n      <td>t</td>\n      <td>...</td>\n      <td>g</td>\n      <td>t</td>\n      <td>t</td>\n      <td>t</td>\n      <td>t</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>ei</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>g</td>\n      <td>c</td>\n      <td>t</td>\n      <td>c</td>\n      <td>a</td>\n      <td>g</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>...</td>\n      <td>c</td>\n      <td>t</td>\n      <td>t</td>\n      <td>g</td>\n      <td>a</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>t</td>\n      <td>ei</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3185</th>\n      <td>t</td>\n      <td>c</td>\n      <td>t</td>\n      <td>c</td>\n      <td>t</td>\n      <td>t</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>t</td>\n      <td>...</td>\n      <td>t</td>\n      <td>c</td>\n      <td>c</td>\n      <td>t</td>\n      <td>c</td>\n      <td>t</td>\n      <td>c</td>\n      <td>t</td>\n      <td>t</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>3186</th>\n      <td>g</td>\n      <td>a</td>\n      <td>g</td>\n      <td>c</td>\n      <td>t</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>a</td>\n      <td>g</td>\n      <td>...</td>\n      <td>g</td>\n      <td>c</td>\n      <td>a</td>\n      <td>c</td>\n      <td>a</td>\n      <td>g</td>\n      <td>c</td>\n      <td>t</td>\n      <td>g</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>3187</th>\n      <td>t</td>\n      <td>c</td>\n      <td>t</td>\n      <td>c</td>\n      <td>g</td>\n      <td>g</td>\n      <td>g</td>\n      <td>g</td>\n      <td>g</td>\n      <td>c</td>\n      <td>...</td>\n      <td>g</td>\n      <td>t</td>\n      <td>g</td>\n      <td>t</td>\n      <td>g</td>\n      <td>t</td>\n      <td>g</td>\n      <td>t</td>\n      <td>c</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>3188</th>\n      <td>a</td>\n      <td>t</td>\n      <td>t</td>\n      <td>c</td>\n      <td>t</td>\n      <td>a</td>\n      <td>c</td>\n      <td>t</td>\n      <td>t</td>\n      <td>a</td>\n      <td>...</td>\n      <td>c</td>\n      <td>c</td>\n      <td>a</td>\n      <td>a</td>\n      <td>a</td>\n      <td>a</td>\n      <td>c</td>\n      <td>a</td>\n      <td>a</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>3189</th>\n      <td>a</td>\n      <td>g</td>\n      <td>g</td>\n      <td>c</td>\n      <td>t</td>\n      <td>g</td>\n      <td>c</td>\n      <td>c</td>\n      <td>t</td>\n      <td>a</td>\n      <td>...</td>\n      <td>a</td>\n      <td>g</td>\n      <td>t</td>\n      <td>a</td>\n      <td>c</td>\n      <td>c</td>\n      <td>a</td>\n      <td>t</td>\n      <td>t</td>\n      <td>n</td>\n    </tr>\n  </tbody>\n</table>\n<p>3190 rows × 61 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from test.resources.data.splice_junction import get_indices\n",
    "from test.resources.data import get_dataset_dataframe\n",
    "\n",
    "original_data = get_dataset_dataframe(\"splice_junction\")\n",
    "original_data.columns = get_indices() + ['target',]\n",
    "original_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "      0    1    2    3    4    5    6    7    8    9    ...  231  232  233  \\\n0       0    1    0    0    0    1    0    0    1    0  ...    0    0    0   \n1       1    0    0    0    0    0    1    0    1    0  ...    0    0    0   \n2       0    0    1    0    1    0    0    0    0    0  ...    0    0    0   \n3       0    0    1    0    0    0    1    0    0    0  ...    0    0    1   \n4       0    0    1    0    0    1    0    0    0    0  ...    0    0    1   \n...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n3185    0    0    0    1    0    1    0    0    0    0  ...    0    0    0   \n3186    0    0    1    0    1    0    0    0    0    0  ...    0    0    0   \n3187    0    0    0    1    0    1    0    0    0    0  ...    0    0    0   \n3188    1    0    0    0    0    0    0    1    0    0  ...    0    1    0   \n3189    1    0    0    0    0    0    1    0    0    0  ...    0    0    0   \n\n      234  235  236  237  238  239  240  \n0       0    1    0    0    1    0    0  \n1       1    0    0    1    0    0    0  \n2       0    1    0    0    1    0    0  \n3       0    0    0    1    0    0    0  \n4       0    0    0    0    0    1    0  \n...   ...  ...  ...  ...  ...  ...  ...  \n3185    0    1    0    0    0    1    2  \n3186    0    1    0    0    1    0    2  \n3187    0    1    0    1    0    0    2  \n3188    0    0    1    0    0    0    2  \n3189    0    1    0    0    0    1    2  \n\n[3190 rows x 241 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>231</th>\n      <th>232</th>\n      <th>233</th>\n      <th>234</th>\n      <th>235</th>\n      <th>236</th>\n      <th>237</th>\n      <th>238</th>\n      <th>239</th>\n      <th>240</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3185</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3186</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3187</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3188</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3189</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>3190 rows × 241 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from test.resources.data import get_splice_junction_processed_dataset\n",
    "\n",
    "data = get_splice_junction_processed_dataset('data')\n",
    "train, test = train_test_split(data, train_size=2/3, random_state=SEED, stratify=data.iloc[:, -1])\n",
    "train_x, train_y = train.iloc[:, :-1], train.iloc[:, -1:]\n",
    "test_x, test_y = test.iloc[:, :-1], test.iloc[:, -1:]\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splice-junction knowledge"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EI-stop ::- @-3 'TAA'.\n",
      "EI-stop ::- @-3 'TAG'.\n",
      "EI-stop ::- @-3 'TGA'.\n",
      "EI-stop ::- @-4 'TAA'.\n",
      "EI-stop ::- @-4 'TAG'.\n",
      "EI-stop ::- @-4 'TGA'.\n",
      "EI-stop ::- @-5 'TAA'.\n",
      "EI-stop ::- @-5 'TAG'.\n",
      "EI-stop ::- @-5 'TGA'.\n",
      "IE-stop ::- @1 'TAA'.\n",
      "IE-stop ::- @1 'TAG'.\n",
      "IE-stop ::- @1 'TGA'.\n",
      "IE-stop ::- @2 'TAA'.\n",
      "IE-stop ::- @2 'TAG'.\n",
      "IE-stop ::- @2 'TGA'.\n",
      "IE-stop ::- @3 'TAA'.\n",
      "IE-stop ::- @3 'TAG'.\n",
      "IE-stop ::- @3 'TGA'.\n",
      "pyramidine-rich :- 6 of (@-15 'YYYYYYYYYY').\n",
      "EI :- @-3 'MAGGTRAGT', not(EI-stop).\n",
      "IE :- pyramidine-rich, @-3 'YAGG', not(IE-stop).\n"
     ]
    }
   ],
   "source": [
    "original_rules = get_rules(\"splice_junction\")\n",
    "\n",
    "for rule in original_rules:\n",
    "    print(rule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from test.resources.data import get_splice_junction_extended_feature_mapping\n",
    "from test.resources.rules import get_splice_junction_formulae\n",
    "\n",
    "variable_mapping = get_splice_junction_extended_feature_mapping()\n",
    "formulae = get_splice_junction_formulae('kb')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splice-junction predictor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 240)]             0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 64)                15424     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,603\n",
      "Trainable params: 17,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input((240,))\n",
    "x = Dense(64, activation='relu')(input_layer)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(3, activation='softmax')(x)\n",
    "\n",
    "predictor = Model(input_layer, x)\n",
    "predictor.compile('adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "predictor.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Injection via Network Composer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "injector = NetworkComposer(predictor, variable_mapping)\n",
    "structured_predictor = injector.inject(formulae)\n",
    "structured_predictor.compile('adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "67/67 [==============================] - 5s 4ms/step - loss: 0.8383 - accuracy: 0.6082\n",
      "Epoch 2/50\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8410\n",
      "Epoch 3/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.2632 - accuracy: 0.9083\n",
      "Epoch 4/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.1857 - accuracy: 0.9351\n",
      "Epoch 5/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.1547 - accuracy: 0.9548\n",
      "Epoch 6/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.1329 - accuracy: 0.9610\n",
      "Epoch 7/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.1157 - accuracy: 0.9638\n",
      "Epoch 8/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0998 - accuracy: 0.9699\n",
      "Epoch 9/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0775 - accuracy: 0.9821\n",
      "Epoch 10/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0717 - accuracy: 0.9817\n",
      "Epoch 11/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.9845\n",
      "Epoch 12/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0597 - accuracy: 0.9868\n",
      "Epoch 13/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0519 - accuracy: 0.9868\n",
      "Epoch 14/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0524 - accuracy: 0.9882\n",
      "Epoch 15/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9920\n",
      "Epoch 16/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9911\n",
      "Epoch 17/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 0.9906\n",
      "Epoch 18/50\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9948\n",
      "Epoch 19/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 0.9944\n",
      "Epoch 20/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0188 - accuracy: 0.9934\n",
      "Epoch 21/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0201 - accuracy: 0.9944\n",
      "Epoch 22/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 0.9948\n",
      "Epoch 23/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 0.9958\n",
      "Epoch 24/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0129 - accuracy: 0.9958\n",
      "Epoch 25/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9972\n",
      "Epoch 26/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 0.9981\n",
      "Epoch 27/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0107 - accuracy: 0.9967\n",
      "Epoch 28/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9981\n",
      "Epoch 29/50\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9972\n",
      "Epoch 30/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9976\n",
      "Epoch 31/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.9991\n",
      "Epoch 32/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9976\n",
      "Epoch 33/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9962\n",
      "Epoch 34/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 35/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.9991\n",
      "Epoch 36/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.9976\n",
      "Epoch 37/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 0.9991\n",
      "Epoch 38/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.9976\n",
      "Epoch 39/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 40/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9976\n",
      "Epoch 41/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.9995\n",
      "Epoch 42/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.9995\n",
      "Epoch 43/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.9991\n",
      "Epoch 44/50\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 0.9991\n",
      "Epoch 45/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 46/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.9981\n",
      "Epoch 47/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.9981\n",
      "Epoch 48/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "Epoch 49/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9972\n",
      "Epoch 50/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0154 - accuracy: 0.9953\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x288eef9a0>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_predictor.fit(train_x, train_y, epochs=50, batch_size=32, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9455\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9454887509346008"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = structured_predictor.evaluate(test_x, test_y)\n",
    "\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Without prior knowledge"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "67/67 [==============================] - 0s 522us/step - loss: 0.8981 - accuracy: 0.5682\n",
      "Epoch 2/50\n",
      "67/67 [==============================] - 0s 539us/step - loss: 0.4561 - accuracy: 0.8354\n",
      "Epoch 3/50\n",
      "67/67 [==============================] - 0s 497us/step - loss: 0.2708 - accuracy: 0.9069\n",
      "Epoch 4/50\n",
      "67/67 [==============================] - 0s 593us/step - loss: 0.1866 - accuracy: 0.9436\n",
      "Epoch 5/50\n",
      "67/67 [==============================] - 0s 493us/step - loss: 0.1651 - accuracy: 0.9483\n",
      "Epoch 6/50\n",
      "67/67 [==============================] - 0s 499us/step - loss: 0.1352 - accuracy: 0.9595\n",
      "Epoch 7/50\n",
      "67/67 [==============================] - 0s 469us/step - loss: 0.1120 - accuracy: 0.9699\n",
      "Epoch 8/50\n",
      "67/67 [==============================] - 0s 546us/step - loss: 0.0893 - accuracy: 0.9751\n",
      "Epoch 9/50\n",
      "67/67 [==============================] - 0s 471us/step - loss: 0.0805 - accuracy: 0.9774\n",
      "Epoch 10/50\n",
      "67/67 [==============================] - 0s 472us/step - loss: 0.0865 - accuracy: 0.9741\n",
      "Epoch 11/50\n",
      "67/67 [==============================] - 0s 465us/step - loss: 0.0718 - accuracy: 0.9798\n",
      "Epoch 12/50\n",
      "67/67 [==============================] - 0s 469us/step - loss: 0.0548 - accuracy: 0.9859\n",
      "Epoch 13/50\n",
      "67/67 [==============================] - 0s 471us/step - loss: 0.0526 - accuracy: 0.9873\n",
      "Epoch 14/50\n",
      "67/67 [==============================] - 0s 482us/step - loss: 0.0454 - accuracy: 0.9868\n",
      "Epoch 15/50\n",
      "67/67 [==============================] - 0s 472us/step - loss: 0.0364 - accuracy: 0.9901\n",
      "Epoch 16/50\n",
      "67/67 [==============================] - 0s 454us/step - loss: 0.0297 - accuracy: 0.9939\n",
      "Epoch 17/50\n",
      "67/67 [==============================] - 0s 458us/step - loss: 0.0282 - accuracy: 0.9934\n",
      "Epoch 18/50\n",
      "67/67 [==============================] - 0s 485us/step - loss: 0.0262 - accuracy: 0.9944\n",
      "Epoch 19/50\n",
      "67/67 [==============================] - 0s 460us/step - loss: 0.0261 - accuracy: 0.9958\n",
      "Epoch 20/50\n",
      "67/67 [==============================] - 0s 472us/step - loss: 0.0211 - accuracy: 0.9948\n",
      "Epoch 21/50\n",
      "67/67 [==============================] - 0s 468us/step - loss: 0.0214 - accuracy: 0.9934\n",
      "Epoch 22/50\n",
      "67/67 [==============================] - 0s 547us/step - loss: 0.0136 - accuracy: 0.9962\n",
      "Epoch 23/50\n",
      "67/67 [==============================] - 0s 477us/step - loss: 0.0146 - accuracy: 0.9972\n",
      "Epoch 24/50\n",
      "67/67 [==============================] - 0s 461us/step - loss: 0.0135 - accuracy: 0.9972\n",
      "Epoch 25/50\n",
      "67/67 [==============================] - 0s 460us/step - loss: 0.0102 - accuracy: 0.9972\n",
      "Epoch 26/50\n",
      "67/67 [==============================] - 0s 468us/step - loss: 0.0119 - accuracy: 0.9967\n",
      "Epoch 27/50\n",
      "67/67 [==============================] - 0s 449us/step - loss: 0.0110 - accuracy: 0.9972\n",
      "Epoch 28/50\n",
      "67/67 [==============================] - 0s 465us/step - loss: 0.0112 - accuracy: 0.9967\n",
      "Epoch 29/50\n",
      "67/67 [==============================] - 0s 492us/step - loss: 0.0068 - accuracy: 0.9981\n",
      "Epoch 30/50\n",
      "67/67 [==============================] - 0s 484us/step - loss: 0.0104 - accuracy: 0.9962\n",
      "Epoch 31/50\n",
      "67/67 [==============================] - 0s 480us/step - loss: 0.0070 - accuracy: 0.9981\n",
      "Epoch 32/50\n",
      "67/67 [==============================] - 0s 469us/step - loss: 0.0120 - accuracy: 0.9958\n",
      "Epoch 33/50\n",
      "67/67 [==============================] - 0s 458us/step - loss: 0.0080 - accuracy: 0.9972\n",
      "Epoch 34/50\n",
      "67/67 [==============================] - 0s 471us/step - loss: 0.0047 - accuracy: 0.9991\n",
      "Epoch 35/50\n",
      "67/67 [==============================] - 0s 464us/step - loss: 0.0074 - accuracy: 0.9962\n",
      "Epoch 36/50\n",
      "67/67 [==============================] - 0s 427us/step - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 37/50\n",
      "67/67 [==============================] - 0s 459us/step - loss: 0.0040 - accuracy: 0.9991\n",
      "Epoch 38/50\n",
      "67/67 [==============================] - 0s 430us/step - loss: 0.0066 - accuracy: 0.9986\n",
      "Epoch 39/50\n",
      "67/67 [==============================] - 0s 469us/step - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 40/50\n",
      "67/67 [==============================] - 0s 462us/step - loss: 0.0101 - accuracy: 0.9962\n",
      "Epoch 41/50\n",
      "67/67 [==============================] - 0s 427us/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 42/50\n",
      "67/67 [==============================] - 0s 469us/step - loss: 0.0085 - accuracy: 0.9981\n",
      "Epoch 43/50\n",
      "67/67 [==============================] - 0s 443us/step - loss: 0.0052 - accuracy: 0.9981\n",
      "Epoch 44/50\n",
      "67/67 [==============================] - 0s 472us/step - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 45/50\n",
      "67/67 [==============================] - 0s 467us/step - loss: 0.0093 - accuracy: 0.9981\n",
      "Epoch 46/50\n",
      "67/67 [==============================] - 0s 467us/step - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 47/50\n",
      "67/67 [==============================] - 0s 481us/step - loss: 0.0062 - accuracy: 0.9972\n",
      "Epoch 48/50\n",
      "67/67 [==============================] - 0s 461us/step - loss: 0.0055 - accuracy: 0.9981\n",
      "Epoch 49/50\n",
      "67/67 [==============================] - 0s 463us/step - loss: 0.0097 - accuracy: 0.9976\n",
      "Epoch 50/50\n",
      "67/67 [==============================] - 0s 468us/step - loss: 0.0091 - accuracy: 0.9972\n",
      "34/34 [==============================] - 0s 354us/step - loss: 0.2683 - accuracy: 0.9398\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9398496150970459"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(train_x, train_y, epochs=50, batch_size=32, verbose=1)\n",
    "loss, accuracy = predictor.evaluate(test_x, test_y)\n",
    "\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}