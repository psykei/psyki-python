---
title: Introduction
author: mmagnini
date: 2023-09-12 12:00:00 +0100
categories: [Technology, Documentation]
tags: [PSyKI]
img_path: /assets/img/
pin: true
math: true
mermaid: true
---

### What is PSyKI?

PSyKI (<u><b>P</b></u>latform for <u><b>Sy</b></u>mbolic <u><b>K</b></u>nowledge <u><b>I</b></u>njection) is a python library for symbolic knowledge injection (<b>SKI</b>).
SKI is a particular subclass of neuro-symbolic (<b>NeSy</b>) integration techniques.
PSyKI offers SKI algorithms (a.k.a. <b>injectors</b>) along with quality of service metrics (<b>QoS</b>).

[Here](https://link.springer.com/chapter/10.1007/978-3-031-15565-9_6) you can have a look at the original paper for more details.

If you use one or more of the features provided by PSyKI, please consider citing this work.

Bibtex: 
```bibtex
@incollection{psyki-extraamas2022,
    author = {Magnini, Matteo and Ciatto, Giovanni and Omicini, Andrea},
    booktitle = {Explainable and Transparent AI and Multi-Agent Systems},
    chapter = 6,
    dblp = {conf/atal/MagniniCO22},
    doi = {10.1007/978-3-031-15565-9_6},
    editor = {Calvaresi, Davide and Najjar, Amro and Winikoff, Michael and Fr√§mling, Kary},
    eisbn = {978-3-031-15565-9},
    eissn = {1611-3349},
    iris = {11585/899511},
    isbn = {978-3-031-15564-2},
    issn = {0302-9743},
    keywords = {Symbolic Knowledge Injection, Explainable AI, XAI, Neural Networks, PSyKI},
    note = {4th International Workshop, EXTRAAMAS 2022, Virtual Event, May 9--10, 2022, Revised Selected Papers},
    pages = {90--108},
    publisher = {Springer},
    scholar = {7587528289517313138},
    scopus = {2-s2.0-85138317005},
    series = {Lecture Notes in Computer Science},
    title = {On the Design of {PSyKI}: a Platform for Symbolic Knowledge Injection into Sub-Symbolic Predictors},
    url = {https://link.springer.com/chapter/10.1007/978-3-031-15565-9_6},
    urlpdf = {https://link.springer.com/content/pdf/10.1007/978-3-031-15565-9_6.pdf},
    volume = 13283,
    wos = {000870042100006},
    year = 2022
}
```

## Overview

Premise: the knowledge that we consider is symbolic, and it is represented with formal logic.
In particular, we use the Prolog formalism to express logic rules.

Note: some aspects of the <b>Prolog</b> language are not fully supported.
Generally, every SKI method specifies which kind of knowledge can support.

### SKI workflow

SKI methods require common steps for knowledge preprocessing.
First, the knowledge is parsed into a visitable data structure (e.g., abstract syntax tree).
Then, it is fuzzified.
This means that from a <i>crispy</i> domain -- logic rules can be only true or false -- the knowledge becomes <i>fuzzy</i> --- there can be multiple degree of truth.
Finally, the knowledge can be injected into the neural network (<b>NN</b>).

In the literature, there are mainly two families of SKI methods:
- <b>structuring</b>, the knowledge is mapped into new neurons and connections of the neural network.
The new components mimic the behaviour of the prior knowledge.
After the injection, the network is still trained (knowledge fitting).
![SKI structuring](injection-structuring.png)
- <b>constraining</b>, the knowledge is embedded in the loss function.
Typically, a cost factor is added to the loss function.
The cost factor is higher the higher is the violation of the knowledge.
In this way, the network learn to avoid predictions that violates the prior knowledge during the training phase.
![SKI constraining](injection-constraining.png)

### Architecture

![PSyKI class diagram](https://www.plantuml.com/plantuml/svg/TLF1Rjim3BthAnvyweQvGA_1C7Gx32YMvTBUYc9WPDdH8ec1H6z8i_pxP3bnd64z9NmKtoCVwVia5ANtJgcqjM57aJoS3KRsEmEEic6bTgItr1auxgm-A0NGEaaaBVZAqVUE3XbJm541WSLWpIBimUtvWGA0XeIG2tijVJG5QZc2HcB4tWsW2KqXKOEGTfGIdZQ6u_vGAfnDydnYVS4sy6zdciwC0bRBSnRu01la1QsXGUY7fzt_qeNxb3mgXPCCghiAx-iQLQYczjNnOaCswjg4X_3JQE5O6lpEZN7OHJEeSHoWHube-zTNsrfJ05iARavwKdxUBSRIkOtHTXi1jvF2Od55Z3wOfjSaffaRD_dsxM7rEBfcWy3HliWVvm-MoyCy_l9vjHehMiSaO6ywciKTUK_p5gjDFfHObyCnOc82jyD48DTnjBBngG8bhEuKHdhStfQeT3S6fG4RjSjyAC-rmZGqFlwfwu9erALg_3lIJV1oURMboV3qpyMUyN5C_BB9oiqRLvMNGc7_ncNFDugdI26rcI0XxVsQtUcWqzb-1Y7rwthANdyDc2smp74vnkpHfyaCTN4bMvUpipwKkiyKlNT_0G00)
*Class diagram representing the relations between `Injector`, `Theory` and `Fuzzifier` classes*

<!--
To generate/edit the class diagram browse the URL above, after replacing `svg` with `uml`
-->

The core abstractions of PSyKI are the following:

 - `Injector`: a SKI algorithm;
 - `Theory`: symbolic knowledge plus additional information about the domain;
 - `Fuzzifier`: entity that transforms (fuzzify) symbolic knowledge into a sub-symbolic data structure.

The class `Theory` is built upon the symbolic knowledge and the metadata of the dataset (extracted by a Pandas `DataFrame`).
The knowledge can be generated by an adapter that parses the Prolog theory (e.g., a `.pl` file, a string) and generates a list of `Formula` objects.
Each `Injector` has one `Fuzzifier`.
The `Fuzzifier` is used to transform the `Theory` into a sub-symbolic data structure (e.g., ad-hoc layers of a NN).
Different fuzzifiers encode the knowledge in different ways.

Name convention:

 - <b>rule</b> is a single logic clause;
 - <b>knowledge</b> is the set of rules;
 - <b>theory</b> is the knowledge plus metadata.


## Features

### Injectors

- <b><i>KBANN</i></b>: Knowledge-Based Artificial Network Networks (see [post]({% post_url 2023-09-13-kbann %}))
- <b><i>KINS</i></b>: Knowledge Injection via Network Structuring (see [post]({% post_url 2023-09-13-kins %}))
- <b><i>KINS</i></b>: Knowledge Injection via Lambda Layer (see [post]({% post_url 2023-09-13-kill %}))

### QoS

- <b><i>Memory Footprint</i></b>
- <b><i>Energy Consumption</i></b>
- <b><i>Latency</i></b>
- <b><i>Data Efficiency</i></b>

For more details about QoS have a look at the corresponding [post]({% post_url 2023-09-13-metrics %}).

## Additional information

### Demo

See the [demo post]({% post_url 2023-09-13-demo %}) to learn how to quickly use PSyKI in your projects.

### Contributors

See the [contributors post]({% post_url 2023-09-13-contributors %}). 

### Developers

External contributions are welcome!
Working with PSyKI codebase requires a number of tools to be installed:
* Python 3.9+
* JDK 11+ (please ensure the `JAVA_HOME` environment variable is properly configured)
* Git 2.20+

#### Develop PSyKI with PyCharm

To participate in the development of PSyKI, we suggest the [PyCharm](https://www.jetbrains.com/pycharm/) IDE.

#### Importing the project

1. Clone this repository in a folder of your preference using `git_clone` appropriately
2. Open PyCharm
3. Select `Open`
4. Navigate your file system and find the folder where you cloned the repository
5. Click `Open`

#### Developing the project

Contributions to this project are welcome. Just some rules:
* We use [git flow](https://github.com/nvie/gitflow), so if you write new features, please do so in a separate `feature/` branch
* We recommend forking the project, developing your stuff, then contributing back vie pull request
* Commit often
* Stay in sync with the `develop` (or `main`) branch (pull frequently if the build passes)
* Do not introduce low quality or untested code

#### Issue tracking
If you meet some problem in using or developing PSyKI, you are encouraged to signal it through the project
["Issues" section](https://github.com/psykei/psyki-python/issues) on GitHub.
